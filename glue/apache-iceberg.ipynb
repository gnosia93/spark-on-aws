{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb57ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "Setting Glue version to: 3.0\n",
      "Previous number of workers: 5\n",
      "Setting new number of workers to: 2\n",
      "Previous worker type: G.1X\n",
      "Setting new worker type to: G.2X\n",
      "Current idle_timeout is 2880 minutes.\n",
      "idle_timeout has been set to 6000 minutes.\n",
      "Previous region: None\n",
      "Setting new region to: ap-northeast-2\n",
      "Region is set to: ap-northeast-2\n",
      "Current iam_role is None\n",
      "iam_role has been set to arn:aws:iam::499514681453:role/AWSGlueServiceRoleJupyter.\n"
     ]
    }
   ],
   "source": [
    "%glue_version 3.0\n",
    "%number_of_workers 2\n",
    "%worker_type G.2X\n",
    "%idle_timeout 6000\n",
    "%region ap-northeast-2\n",
    "%iam_role arn:aws:iam::499514681453:role/AWSGlueServiceRoleJupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81875c40",
   "metadata": {},
   "source": [
    "https://docs.aws.amazon.com/ko_kr/glue/latest/dg/aws-glue-programming-etl-format-iceberg.html <br>\n",
    "IceBerg 테이블을 생성하기 위해서는 GLUE JOB 실행 파라미터로 --datalake-formats = iceberg 값을 줘야한다. \n",
    "GLUE 콘솔에서 JOB을 등록할때 실행 파라미터 값을 설정하거나, CLI 커맨드를 이용하여 JOB 을 등록할 떄 값을 설정해야 한다.\n",
    "이값을 설정하지 않으면 코드 실행시 glue_catalog 플러그인을 찾을 수 없다는 오류가 발생한다. \n",
    "이에 반해, 이 노트북에서 처럼 glue interactive 모드를 사용하는 경우는 아래와 같이 %%configure 매직을 활용하여 datalake format 이 iceberg 로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b4850e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following configurations have been updated: {'datalake-formats': 'iceberg'}\n"
     ]
    }
   ],
   "source": [
    "%%configure \n",
    "{ \"datalake-formats\":\"iceberg\" }                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ba4032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating with profile=default\n",
      "glue_role_arn defined by user: arn:aws:iam::499514681453:role/AWSGlueServiceRoleJupyter\n",
      "Trying to create a Glue session for the kernel.\n",
      "Worker Type: G.2X\n",
      "Number of Workers: 2\n",
      "Session ID: 90091c52-8d34-4f92-8fae-81eaf1aadfd0\n",
      "Job Type: glueetl\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 0.37.2\n",
      "--enable-glue-datacatalog true\n",
      "--datalake-formats iceberg\n",
      "Waiting for session 90091c52-8d34-4f92-8fae-81eaf1aadfd0 to get into ready status...\n",
      "Session 90091c52-8d34-4f92-8fae-81eaf1aadfd0 has been created.\n",
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "|  sample|             tbl-csv|      false|\n",
      "|  sample|       tbl-flight-p5|      false|\n",
      "|  sample|     tbl-flight-part|      false|\n",
      "|  sample|tbl-flight-part-r...|      false|\n",
      "|  sample|         tbl-flight4|      false|\n",
      "+--------+--------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "show tables in `sample`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f21c84",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.SparkSession.html\n",
    "glue spark 에서 iceberg 테이블을 사용하기 위해서는 아래와 같이 config 를 설정해야 한다. 코드상에 spark 세션의 .config 함수를 활용할 수도 있고,\n",
    "glue job 의 파리미터로 설정할 수도 있다. 지금처럼 인터랙티브 모드로 개발하는 경우에는 spark session 에 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bcbec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=jes appName=GlueReplApp>\n"
     ]
    }
   ],
   "source": [
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\"\"\"\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "SparkSession = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "\"\"\"\n",
    "\n",
    "# Iceberg configuration\n",
    "warehouse_path = 's3://glue-seoul-20230405/iceberg'\n",
    "spark = SparkSession.builder \\\n",
    "    .config('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions') \\\n",
    "    .config('spark.sql.catalog.glue_catalog', 'org.apache.iceberg.spark.SparkCatalog') \\\n",
    "    .config('spark.sql.catalog.glue_catalog.warehouse', warehouse_path) \\\n",
    "    .config('spark.sql.catalog.glue_catalog.catalog-impl', 'org.apache.iceberg.aws.glue.GlueCatalog') \\\n",
    "    .config('spark.sql.catalog.glue_catalog.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "glueContext = GlueContext(sc)\n",
    "#job = Job(glueContext)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67437939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|year|quarter|month|\n",
      "+----+-------+-----+\n",
      "|2016|      4|   10|\n",
      "|2016|      4|   10|\n",
      "|2016|      4|   10|\n",
      "+----+-------+-----+\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "select year, quarter, month from sample.`tbl-flight4` limit 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6bb0bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "create table `glue_catalog`.sample.`iceberg`\n",
    "using iceberg\n",
    "select * from sample.`tbl-flight4`\n",
    "\"\"\"\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5894eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "|  sample|             iceberg|      false|\n",
      "|  sample|             tbl-csv|      false|\n",
      "|  sample|       tbl-flight-p5|      false|\n",
      "|  sample|     tbl-flight-part|      false|\n",
      "|  sample|tbl-flight-part-r...|      false|\n",
      "|  sample|         tbl-flight4|      false|\n",
      "+--------+--------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "show tables in `sample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c66f0eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|           year|   bigint|       |\n",
      "|        quarter|   bigint|       |\n",
      "|          month|   bigint|       |\n",
      "|   day_of_month|   bigint|       |\n",
      "|    day_of_week|   bigint|       |\n",
      "|        fl_date|   string|       |\n",
      "| unique_carrier|   string|       |\n",
      "|     airline_id|   bigint|       |\n",
      "|        carrier|   string|       |\n",
      "|       tail_num|   string|       |\n",
      "|         fl_num|   bigint|       |\n",
      "|   crs_dep_time|   bigint|       |\n",
      "|       dep_time|   bigint|       |\n",
      "|      dep_delay|   bigint|       |\n",
      "|  dep_delay_new|   bigint|       |\n",
      "|      dep_del15|   bigint|       |\n",
      "|dep_delay_group|   bigint|       |\n",
      "|   dep_time_blk|   string|       |\n",
      "|       taxi_out|   bigint|       |\n",
      "|     wheels_off|   bigint|       |\n",
      "+---------------+---------+-------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "describe table `glue_catalog`.sample.`iceberg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c49ab5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 5248439|\n",
      "+--------+\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "select count(1) from `glue_catalog`.sample.`iceberg`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
